{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Immoweb data analysis "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321. connected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "\n",
       "#h2o-table-2.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-2 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-2 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-2 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-2 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-2 .h2o-table th,\n",
       "#h2o-table-2 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-2 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-2\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption></caption>\n",
       "    <thead></thead>\n",
       "    <tbody><tr><td>H2O_cluster_uptime:</td>\n",
       "<td>4 mins 37 secs</td></tr>\n",
       "<tr><td>H2O_cluster_timezone:</td>\n",
       "<td>Europe/Brussels</td></tr>\n",
       "<tr><td>H2O_data_parsing_timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O_cluster_version:</td>\n",
       "<td>3.46.0.1</td></tr>\n",
       "<tr><td>H2O_cluster_version_age:</td>\n",
       "<td>6 days</td></tr>\n",
       "<tr><td>H2O_cluster_name:</td>\n",
       "<td>H2O_from_python_daryc_vrhyhf</td></tr>\n",
       "<tr><td>H2O_cluster_total_nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O_cluster_free_memory:</td>\n",
       "<td>3.886 Gb</td></tr>\n",
       "<tr><td>H2O_cluster_total_cores:</td>\n",
       "<td>16</td></tr>\n",
       "<tr><td>H2O_cluster_allowed_cores:</td>\n",
       "<td>16</td></tr>\n",
       "<tr><td>H2O_cluster_status:</td>\n",
       "<td>locked, healthy</td></tr>\n",
       "<tr><td>H2O_connection_url:</td>\n",
       "<td>http://localhost:54321</td></tr>\n",
       "<tr><td>H2O_connection_proxy:</td>\n",
       "<td>{\"http\": null, \"https\": null}</td></tr>\n",
       "<tr><td>H2O_internal_security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>Python_version:</td>\n",
       "<td>3.12.1 final</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n"
      ],
      "text/plain": [
       "--------------------------  -----------------------------\n",
       "H2O_cluster_uptime:         4 mins 37 secs\n",
       "H2O_cluster_timezone:       Europe/Brussels\n",
       "H2O_data_parsing_timezone:  UTC\n",
       "H2O_cluster_version:        3.46.0.1\n",
       "H2O_cluster_version_age:    6 days\n",
       "H2O_cluster_name:           H2O_from_python_daryc_vrhyhf\n",
       "H2O_cluster_total_nodes:    1\n",
       "H2O_cluster_free_memory:    3.886 Gb\n",
       "H2O_cluster_total_cores:    16\n",
       "H2O_cluster_allowed_cores:  16\n",
       "H2O_cluster_status:         locked, healthy\n",
       "H2O_connection_url:         http://localhost:54321\n",
       "H2O_connection_proxy:       {\"http\": null, \"https\": null}\n",
       "H2O_internal_security:      False\n",
       "Python_version:             3.12.1 final\n",
       "--------------------------  -----------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import H2O and Initialize\n",
    "import h2o\n",
    "from h2o.automl import H2OAutoML\n",
    "from h2o.frame import H2OFrame\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "\n",
    "# Initialize H2O\n",
    "h2o.init()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and replace 'missing' with 'missing_info' and NaN or empty cells with -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modified data saved to: data/data_20240313_modified.csv\n"
     ]
    }
   ],
   "source": [
    "# Load the cleaned data into a DataFrame\n",
    "cleaned_data_path = 'data/data_20240313_cleaned.csv'\n",
    "cleaned_df = pd.read_csv(cleaned_data_path, decimal=',')\n",
    "\n",
    "# Fill empty cells with -1\n",
    "cleaned_df.fillna(-1, inplace=True)\n",
    "\n",
    "# Replace other missing value indicators\n",
    "cleaned_df.replace(['Missing', 'MISSING'], 'missing_info', inplace=True)\n",
    "\n",
    "# Save the modified DataFrame to a CSV file\n",
    "modified_data_path = 'data/data_20240313_modified.csv'\n",
    "cleaned_df.to_csv(modified_data_path, index=False)\n",
    "print(f\"Modified data saved to: {modified_data_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert to pandas DataFrame for outlier removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert modified DataFrame to an H2OFrame\n",
    "df_cleaned = H2OFrame(cleaned_df)\n",
    "\n",
    "# Define the features to check for outliers\n",
    "features_to_check = ['price', 'surface_land_sqm', 'total_area_sqm', 'nbr_bedrooms']\n",
    "\n",
    "# Define the function to calculate IQR bounds within H2OFrame context\n",
    "def calculate_bounds_h2o(data, feature):\n",
    "    Q1 = data[feature].quantile(0.25).as_data_frame().iloc[0,0]\n",
    "    Q3 = data[feature].quantile(0.75).as_data_frame().iloc[0,0]\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    return lower_bound, upper_bound\n",
    "\n",
    "# Apply the outlier removal process for each specified feature within the H2O context\n",
    "for feature in features_to_check:\n",
    "    lower_bound, upper_bound = calculate_bounds_h2o(df_cleaned, feature)\n",
    "    df_cleaned = df_cleaned[(df_cleaned[feature] >= lower_bound) & (df_cleaned[feature] <= upper_bound)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the data into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoML progress: |█\n",
      "09:26:00.738: AutoML: XGBoost is not available; skipping it.\n",
      "\n",
      "██████████████████████████████████████████████████████████████| (done) 100%\n",
      "model_id                                                 rmse          mse       mae       rmsle    mean_residual_deviance\n",
      "GBM_4_AutoML_4_20240320_92600                         56071.4  3.144e+09     38093.1    0.178201               3.144e+09\n",
      "GBM_grid_1_AutoML_4_20240320_92600_model_5            56586.1  3.20199e+09   38503.4    0.180184               3.20199e+09\n",
      "GBM_3_AutoML_4_20240320_92600                         56641.1  3.20821e+09   38878      0.180007               3.20821e+09\n",
      "GBM_2_AutoML_4_20240320_92600                         56881.9  3.23555e+09   39235.3    0.181088               3.23555e+09\n",
      "GBM_1_AutoML_4_20240320_92600                         57167.3  3.2681e+09    39288.2    0.182329               3.2681e+09\n",
      "GBM_5_AutoML_4_20240320_92600                         57611.8  3.31912e+09   40114.1    0.183589               3.31912e+09\n",
      "GBM_grid_1_AutoML_4_20240320_92600_model_4            58404.7  3.41111e+09   39728.3    0.185122               3.41111e+09\n",
      "GBM_grid_1_AutoML_4_20240320_92600_model_2            58630.4  3.43752e+09   40148.7    0.185553               3.43752e+09\n",
      "GBM_grid_1_AutoML_4_20240320_92600_model_3            59871.5  3.58459e+09   40379.6    0.1922                 3.58459e+09\n",
      "GBM_grid_1_AutoML_4_20240320_92600_model_1            60815.7  3.69855e+09   42694.4    0.192198               3.69855e+09\n",
      "DRF_1_AutoML_4_20240320_92600                         63373.4  4.01619e+09   43070.9    0.199419               4.01619e+09\n",
      "XRT_1_AutoML_4_20240320_92600                         64839.1  4.20411e+09   44932.6    0.206909               4.20411e+09\n",
      "DeepLearning_1_AutoML_4_20240320_92600                78083.5  6.09704e+09   54127.9  nan                      6.09704e+09\n",
      "GLM_1_AutoML_4_20240320_92600                        130711    1.70853e+10  101907      0.428217               1.70853e+10\n",
      "DeepLearning_grid_1_AutoML_4_20240320_92600_model_1  206045    4.24546e+10   58131.2  nan                      4.24546e+10\n",
      "[15 rows x 6 columns]\n",
      "\n",
      "gbm prediction progress: |███████████████████████████████████████████████████████| (done) 100%\n",
      "  predict\n",
      "   131388\n",
      "   400777\n",
      "   427198\n",
      "   340823\n",
      "   375817\n",
      "   146890\n",
      "   187533\n",
      "   358309\n",
      "   185071\n",
      "   313738\n",
      "[10 rows x 1 column]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Split the cleaned data into training and testing sets\n",
    "train, test = df_cleaned.split_frame(ratios=[.8], seed=42)\n",
    "\n",
    "# Specify Target and Predictor Variables 'price' is the target variable\n",
    "target = 'price'\n",
    "predictors = df_cleaned.columns\n",
    "predictors.remove(target)\n",
    "\n",
    "# Ensure you use `train` for AutoML, which now contains the cleaned data\n",
    "aml = H2OAutoML(max_models=20, seed=42, max_runtime_secs=600)\n",
    "aml.train(x=predictors, y=target, training_frame=train)\n",
    "\n",
    "# View the AutoML Leaderboard\n",
    "lb = aml.leaderboard\n",
    "print(lb.head(rows=lb.nrows))  # Print all rows instead of default (10 rows)\n",
    "\n",
    "# Make Predictions\n",
    "predictions = aml.leader.predict(test)\n",
    "print(predictions.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the AutoML Leader Model, save predictions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to: D:\\Github\\Projects\\immo-eliza-ml\\my_model_path\\GBM_4_AutoML_4_20240320_92600\n"
     ]
    }
   ],
   "source": [
    "# Save the model\n",
    "model_path = h2o.save_model(model=aml.leader, path=\"my_model_path\", force=True)\n",
    "print(f\"Model saved to: {model_path}\")\n",
    "\n",
    "# Save predictions to a CSV file\n",
    "predictions_path = \"predictions_AutoML.csv\"\n",
    "h2o.export_file(predictions, path=predictions_path, force=True)\n",
    "print(f\"Predictions saved to: {predictions_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the Model and Making Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gbm prediction progress: |███████████████████████████████████████████████████████| (done) 100%\n",
      "  predict\n",
      "   131388\n",
      "   400777\n",
      "   427198\n",
      "   340823\n",
      "   375817\n",
      "   146890\n",
      "   187533\n",
      "   358309\n",
      "   185071\n",
      "   313738\n",
      "[10 rows x 1 column]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the saved model\n",
    "try:\n",
    "    loaded_model = h2o.load_model(path=model_path)\n",
    "    # Assuming you have a dataset to predict\n",
    "    predictions = loaded_model.predict(test)\n",
    "    print(predictions.head())\n",
    "except Exception as e:\n",
    "    print(\"An error occurred while loading the model or making predictions:\", e)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         predict\n",
      "0  131388.051656\n",
      "1  400776.737004\n",
      "2  427197.953980\n",
      "3  340822.525499\n",
      "4  375816.987828\n"
     ]
    }
   ],
   "source": [
    "predictions_df = pd.read_csv(\"predictions_AutoML.csv\")\n",
    "\n",
    "# Examine the first few rows\n",
    "print(predictions_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Github\\Projects\\immo-eliza-ml\\venv\\Lib\\site-packages\\h2o\\frame.py:1983: H2ODependencyWarning: Converting H2O frame to pandas dataframe using single-thread.  For faster conversion using multi-thread, install datatable (for Python 3.9 or lower), or polars and pyarrow (for Python 3.10 or above) and activate it using:\n",
      "\n",
      "with h2o.utils.threading.local_context(polars_enabled=True, datatable_enabled=True):\n",
      "    pandas_df = h2o_df.as_data_frame()\n",
      "\n",
      "  warnings.warn(\"Converting H2O frame to pandas dataframe using single-thread.  For faster conversion using\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 2952608966.817194\n",
      "Root Mean Squared Error (RMSE): 54337.914634417044\n",
      "Mean Absolute Error (MAE): 37062.96518401191\n",
      "R-squared (R2): 0.8212804436379184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Github\\Projects\\immo-eliza-ml\\venv\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Calculate evaluation metrics\n",
    "actuals = test[target].as_data_frame().values.flatten()  \n",
    "\n",
    "mse = mean_squared_error(actuals, predictions_df['predict'])\n",
    "rmse = mean_squared_error(actuals, predictions_df['predict'], squared=False)\n",
    "mae = mean_absolute_error(actuals, predictions_df['predict'])\n",
    "r2 = r2_score(actuals, predictions_df['predict'])\n",
    "\n",
    "# Print the metrics\n",
    "print(f'Mean Squared Error (MSE): {mse}')\n",
    "print(f'Root Mean Squared Error (RMSE): {rmse}')\n",
    "print(f'Mean Absolute Error (MAE): {mae}')\n",
    "print(f'R-squared (R2): {r2}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
